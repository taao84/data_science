{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dictionary\n",
    "\n",
    "* **survival: **  Survival        0 = No, 1 = Yes           \n",
    "* **pclass: **    Ticket class    1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "* **sex: **       Sex                                       \n",
    "* **Age: ** \t    Age in years \t\n",
    "* **sibsp: **     # of siblings / spouses aboard the Titanic \t\n",
    "* **parch: **     # of parents / children aboard the Titanic \t\n",
    "* **ticket: **    Ticket number \t\n",
    "* **fare: **      Passenger fare \t\n",
    "* **cabin: **     Cabin number \t\n",
    "* **embarked: **  Port of Embarkation \tC = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDimensions train dataset: \u001b[0m (891, 12)\n",
      "\u001b[1mDimensions test dataset: \u001b[0m (418, 11)\n",
      "\u001b[1mProportion of null values per whole TRAIN dataset: \u001b[0m\n",
      "PassengerId     0.0\n",
      "Survived        0.0\n",
      "Pclass          0.0\n",
      "Name            0.0\n",
      "Sex             0.0\n",
      "Age            20.0\n",
      "SibSp           0.0\n",
      "Parch           0.0\n",
      "Ticket          0.0\n",
      "Fare            0.0\n",
      "Cabin          77.0\n",
      "Embarked        0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "#print \"TensorFlow version: \", tf.__version__\n",
    "\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "#print list(train_data.columns.values)\n",
    "\n",
    "print color.BOLD + 'Dimensions train dataset: ' + color.END, train_data.shape\n",
    "print color.BOLD + 'Dimensions test dataset: ' + color.END, test_data.shape\n",
    "\n",
    "#print color.BOLD + 'Train dataset NULL values per column: ' + color.END\n",
    "trainNullValuesPerColumn = train_data.isnull().sum()\n",
    "#print trainNullValuesPerColumn\n",
    "print (color.BOLD + 'Proportion of null values per whole TRAIN dataset: ' + color.END)\n",
    "print ((trainNullValuesPerColumn/train_data.shape[0]).round(2) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDimensions test dataset: \u001b[0m\n",
      "(418, 11)\n",
      "\u001b[1mProportion of null values per whole TEST dataset: \u001b[0m\n",
      "PassengerId     0.0\n",
      "Pclass          0.0\n",
      "Name            0.0\n",
      "Sex             0.0\n",
      "Age            10.0\n",
      "SibSp           0.0\n",
      "Parch           0.0\n",
      "Ticket          0.0\n",
      "Fare            0.0\n",
      "Cabin          37.0\n",
      "Embarked        0.0\n",
      "dtype: float64\n",
      "\u001b[1mDimensions train dataset: \u001b[0m (891, 12)\n",
      "\u001b[1mDimensions test dataset: \u001b[0m (418, 11)\n"
     ]
    }
   ],
   "source": [
    "print (color.BOLD + 'Dimensions test dataset: ' + color.END)\n",
    "print (test_data.shape)\n",
    "#print color.BOLD + 'Test dataset NULL values per column: ' + color.END\n",
    "testNullValuesPerColumn = test_data.isnull().sum()\n",
    "#print testNullValuesPerColumn\n",
    "print (color.BOLD + 'Proportion of null values per whole TEST dataset: ' + color.END)\n",
    "print ((testNullValuesPerColumn/train_data.shape[0]).round(2) * 100)\n",
    "\n",
    "print color.BOLD + 'Dimensions train dataset: ' + color.END, train_data.shape\n",
    "print color.BOLD + 'Dimensions test dataset: ' + color.END, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create another version of the dataset dropping the **Cabin** and the **Name** column and then removing the rows with NULL age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Original Train: ', (891, 12), ' - New Train: ', (712, 10))\n",
      "('Original Test: ', (418, 11), ' - New Test: ', (418, 9))\n",
      "\u001b[1mDimensions train dataset: \u001b[0m (712, 10)\n",
      "\u001b[1mDimensions test dataset: \u001b[0m (418, 9)\n"
     ]
    }
   ],
   "source": [
    "train_data_2 = train_data.drop(axis=1, columns=['Cabin', 'Name']).dropna(0)\n",
    "test_data_2 = test_data.drop(axis=1, columns=['Cabin', 'Name'])\n",
    "\n",
    "print ('Original Train: ', train_data.shape, ' - New Train: ', train_data_2.shape)\n",
    "print ('Original Test: ', test_data.shape, ' - New Test: ', test_data_2.shape)\n",
    "\n",
    "print color.BOLD + 'Dimensions train dataset: ' + color.END, train_data_2.shape\n",
    "print color.BOLD + 'Dimensions test dataset: ' + color.END, test_data_2.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the 'Ticket' column to more meaninful information\n",
    "What I care about is that if some people share the same ticket I will assume they are part of the same family and then they might have had a better chance to be saved.\n",
    "I'll extract that information by counting the people sharing the same ticket in a new column '**SharingSameTicket**'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TRAIN - ', 'Total rows: ', 712, 'Number of unique tickets: ', 541)\n",
      "('TEST - ', 'Total rows: ', 418, 'Number of unique tickets: ', 363)\n",
      "\u001b[1mDimensions train dataset: \u001b[0m (712, 10)\n",
      "\u001b[1mDimensions test dataset: \u001b[0m (418, 9)\n"
     ]
    }
   ],
   "source": [
    "print (\"TRAIN - \", \"Total rows: \", train_data_2.shape[0], \n",
    "       'Number of unique tickets: ', len(train_data_2['Ticket'].unique()))\n",
    "print (\"TEST - \", \"Total rows: \", test_data_2.shape[0], \n",
    "       'Number of unique tickets: ', len(test_data_2['Ticket'].unique()))\n",
    "\n",
    "train_data_2 = train_data_2.join(train_data_2['Ticket'].value_counts(), on='Ticket', rsuffix='Count')\n",
    "test_data_2 = test_data_2.join(test_data_2['Ticket'].value_counts(), on='Ticket', rsuffix='Count')\n",
    "\n",
    "train_data_2 = train_data_2.drop(axis=1, columns=['Ticket'])\n",
    "test_data_2 = test_data_2.drop(axis=1, columns=['Ticket'])\n",
    "\n",
    "train_data_2.head(5)\n",
    "\n",
    "print color.BOLD + 'Dimensions train dataset: ' + color.END, train_data_2.shape\n",
    "print color.BOLD + 'Dimensions test dataset: ' + color.END, test_data_2.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the 'Sex' and 'Embarqued' columns to a one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDimensions train dataset: \u001b[0m (712, 11)\n",
      "\u001b[1mDimensions test dataset: \u001b[0m (418, 10)\n"
     ]
    }
   ],
   "source": [
    "if 'Sex' in train_data_2.columns:\n",
    "    train_data_2 = pd.get_dummies(train_data_2, columns=[\"Sex\"])\n",
    "    test_data_2 = pd.get_dummies(test_data_2, columns=[\"Sex\"])\n",
    "\n",
    "train_data_2.head(5)\n",
    "\n",
    "print color.BOLD + 'Dimensions train dataset: ' + color.END, train_data_2.shape\n",
    "print color.BOLD + 'Dimensions test dataset: ' + color.END, test_data_2.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the 'Embarqued' columns to a one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDimensions train dataset: \u001b[0m (712, 13)\n",
      "\u001b[1mDimensions test dataset: \u001b[0m (418, 12)\n"
     ]
    }
   ],
   "source": [
    "if 'Embarked' in train_data_2.columns:\n",
    "    train_data_2 = pd.get_dummies(train_data_2, columns=['Embarked'])\n",
    "    test_data_2 = pd.get_dummies(test_data_2, columns=['Embarked'])\n",
    "\n",
    "train_data_2.head(5)\n",
    "\n",
    "print color.BOLD + 'Dimensions train dataset: ' + color.END, train_data_2.shape\n",
    "print color.BOLD + 'Dimensions test dataset: ' + color.END, test_data_2.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop the PassengerId column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDimensions train dataset: \u001b[0m (712, 12)\n",
      "\u001b[1mDimensions test dataset: \u001b[0m (418, 11)\n"
     ]
    }
   ],
   "source": [
    "train_data_2 = train_data_2.drop(axis=1, columns=['PassengerId'])\n",
    "test_data_2 = test_data_2.drop(axis=1, columns=['PassengerId'])\n",
    "train_data_2.head(5)\n",
    "\n",
    "print color.BOLD + 'Dimensions train dataset: ' + color.END, train_data_2.shape\n",
    "print color.BOLD + 'Dimensions test dataset: ' + color.END, test_data_2.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the Kaggle result we need to keep all the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDimensions train dataset: \u001b[0m (712, 12)\n",
      "\u001b[1mDimensions test dataset: \u001b[0m (418, 11)\n"
     ]
    }
   ],
   "source": [
    "test_data_2.fillna(method='ffill', inplace=True)\n",
    "\n",
    "print color.BOLD + 'Dimensions train dataset: ' + color.END, train_data_2.shape\n",
    "print color.BOLD + 'Dimensions test dataset: ' + color.END, test_data_2.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save cleaned and converted file to a new dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDimensions train dataset: \u001b[0m (712, 12)\n",
      "\u001b[1mDimensions test dataset: \u001b[0m (418, 11)\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    train_data_2.to_csv('data/train_final.csv', index=False)\n",
    "    test_data_2.to_csv('data/test_final.csv', index=False)\n",
    "\n",
    "    train_data_final = pd.read_csv(\"data/train_final.csv\")\n",
    "    test_data_final = pd.read_csv(\"data/test_final.csv\")\n",
    "    \n",
    "    train_data_final.head(5)\n",
    "\n",
    "print color.BOLD + 'Dimensions train dataset: ' + color.END, train_data_2.shape\n",
    "print color.BOLD + 'Dimensions test dataset: ' + color.END, test_data_2.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
